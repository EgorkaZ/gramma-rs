use super::{
    tokenizer::{Token::*, *},
    AutomataBuilder, SubNFA, StrEdge, RangeEdge, EpsEdge,
    StatePtr, State, RegistryBuilder, GrammarError,
    UnitId
};
use lalrpop_util::ParseError;

grammar<'input>(nfa: &mut AutomataBuilder, reg: &mut RegistryBuilder);

pub TotalGrammar: StatePtr = {
    Grammar <lex_state:Lexer> =>? {
        reg.assert_units_defined()
            .map_err(GrammarError::Registry)
            .map_err(|error| ParseError::User{ error })
            .map(|_| lex_state)
    },
}

pub Grammar: () = {
    "grammar" <decls:NtDecl*> "grammar_end" => ()
}

NtDecl: UnitId = {
    <mb_sym:"sym"?> <id:Id> ":" <res_type:NtType> "{" <mut rules:(<NtRule> ",")*> <last_rule:NtRule> "}" =>? {
        rules.push(last_rule);
        reg.set_nterm(id, res_type, rules, mb_sym.is_some())
            .map_err(GrammarError::Registry)
            .map_err(|error| ParseError::User{ error })
    }
}

NtType: String = {
    <name:Id> <list:("<" <NtTypeList> ">")?> => {
        let mut name = String::from(name);
        if let Some(list) = list {
            name.push('<');
            list.into_iter()
                .intersperse(String::from(", "))
                .for_each(|sub_type| name.extend(sub_type.chars()));
            name.push('>');
        }
        name
    },
    "(" <list:NtTypeList?> ")" => {
        let mut name = String::new();
        name.push('(');
        if let Some(list) = list {
            let sub_types = list.iter()
                .map(|sub_type| &sub_type[..])
                .intersperse(", ")
                .flat_map(|sub_type| sub_type.chars());
            name.extend(sub_types);
        }
        name.push(')');
        name
    },
}

NtTypeList: Vec<String> = {
    <mut fst:(<NtType> ",")*> <last:NtType> => {
        fst.push(last);
        fst
    }
}

NtRule: (Vec<(UnitId, Option<&'input str>)>, &'input str) = {
    <parts:LabeledId+> <action:Action> => {
        (parts, action)
    }
}

LabeledId: (UnitId, Option<&'input str>) = {
    <label:(<Id> ":")?> <unit_name:Id> => {
        (reg.unit_by_name(unit_name), label)
    }
}

pub Lexer: StatePtr = {
    "lexer" <decls:LexDecl*> "lexer_end" =>? {
        let start = nfa.add_state(State::casual());

        let toks = decls.iter()
            .filter_map(|(mb_tok_name, sub)| mb_tok_name.map(|name: &'input str| (name, sub)));

        for (name, sub) in toks {
            nfa.add_sym(&start, EpsEdge, sub.input());

            reg.set_tok(name)
                .map(|id| nfa.add_state(State::terminal(id)))
                .map(|term: StatePtr| nfa.add_sym(sub.output(), EpsEdge, &term))
                .map_err(|err| ParseError::User{ error: GrammarError::Registry(err) })?;
        }
        Ok(start)
    }
}

LexDecl: (Option<&'input str>, SubNFA) = {
    <tok:("tok"?)> <id:Id> "=" <curr:LexSeq> ";" => {
        (tok.map(|_| id), nfa.define_name(id, SubNFA::clone(&curr)))
    }
}

LexSeq: SubNFA = {
    <seq:LexPrimQual+> => {
        let input = StatePtr::clone(seq[0].input());
        let mut prev_to = seq[0].output();
        for SubNFA(from, to) in seq[1..].iter() {
            prev_to.extend(from);
            prev_to = to;
        }
        SubNFA(input, StatePtr::clone(prev_to))
    },
}

LexAlt: SubNFA = {
    "{" <fst:LexSeq> <rest:("," <LexSeq>)*> "}" => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), EpsEdge, fst.input());
        nfa.add_sym(fst.output(), EpsEdge, curr.output());

        for sub in rest.iter() {
            nfa.add_sym(curr.input(), EpsEdge, sub.input());
            nfa.add_sym(sub.output(), EpsEdge, curr.output());
        }
        curr
    }
}

LexPrimQual: SubNFA = {
    LexPrim,
    <sub:LexPrim> "?" => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), EpsEdge, sub.input());
        nfa.add_sym(sub.output(), EpsEdge, curr.output());
        nfa.add_sym(curr.input(), EpsEdge, curr.output());
        curr
    },
    <sub:LexPrim> "+" => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), EpsEdge, sub.input());
        nfa.add_sym(sub.output(), EpsEdge, curr.output());
        nfa.add_sym(sub.output(), EpsEdge, sub.input());
        curr
    },
    <sub:LexPrim> "*" => {
        let curr = nfa.create_sub();
        // parse "+"
        nfa.add_sym(curr.input(), EpsEdge, sub.input());
        nfa.add_sym(sub.output(), EpsEdge, curr.output());
        nfa.add_sym(sub.output(), EpsEdge, sub.input());
        // and also eps
        nfa.add_sym(curr.input(), EpsEdge, curr.output());
        curr
    },
}

LexPrim: SubNFA = {
    Id => nfa.resolve_id(<>),
    LexAlt,
    Str => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), StrEdge(<>), curr.output());
        curr
    },
    <rng:Rng> => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), RangeEdge::new(rng.0, rng.1), curr.output());
        curr
    },
    "eps" => {
        let curr = nfa.create_sub();
        nfa.add_sym(curr.input(), EpsEdge, curr.output());
        curr
    }
}

extern {
    type Location = usize;
    type Error = GrammarError<'input>;

    enum Token<'input>
    {
        "lexer"       => LexerBegin,
        "lexer_end"   => LexerEnd,
        "tok"         => Tok,
        Id            => Id(<&'input str>),
        "{"           => LBrace,
        "}"           => RBrace,
        Rng           => Range(<char>, <char>),
        Str           => Str(<String>),
        "="           => Eq,
        "?"           => QuestionMark,
        "*"           => Star,
        "+"           => Plus,
        ","           => Comma,
        ";"           => Semicolon,
        "eps"         => Eps,

        "grammar"     => GrammarBegin,
        "grammar_end" => GrammarEnd,
        Action        => FatArrow(<&'input str>),
        ":"           => Colon,
        "sym"         => Sym,
        "<"           => LT,
        ">"           => GT,
        "("           => LPar,
        ")"           => RPar
    }
}
